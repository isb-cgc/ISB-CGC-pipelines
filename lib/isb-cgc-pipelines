#!/usr/bin/env python
import json
import argparse
import subprocess
from pipelines.routes import *
from pipelines.paths import *
from pipelines.config import PipelineConfig
from pipelines.service import PipelineService
from pipelines.scheduler import PipelineScheduler


if __name__ == "__main__":
	parser = argparse.ArgumentParser(description="")
	subparsers = parser.add_subparsers(dest="subcommand")

	jobs = subparsers.add_parser("jobs")
	jobs.add_argument("jobsOperation", choices=["describe", "list", "submit", "edit", "restart", "cancel"])

	dataDisks = subparsers.add_parser("data-disks")
	dataDisks.add_argument("dataDiskOperation", choices=["create", "delete", "list", "describe"])

	config = subparsers.add_parser("config")
	config.add_argument("configOperation", choices=["update", "view"])

	logs = subparsers.add_parser("logs")
	logs.add_argument("logsOperation", choices=["display"])

	scheduler = subparsers.add_parser("scheduler")
	scheduler.add_argument("schedulerOperation", choices=["start", "stop"])
	
	args, unknown = parser.parse_known_args()

	if args.subcommand == "jobs":
		parser = argparse.ArgumentParser()

		if args.jobsOperation == "submit":
			parser.add_argument("--pipeline", required=True)
			parser.add_argument("--imageName", required=True)
			submitGrp = parser.add_mutually_exclusive_group(required=True)
			submitGrp.add_argument("--scriptUrl")
			submitGrp.add_argument("--cmd")
			parser.add_argument("--logsPath", required=True)
			parser.add_argument("--diskSize", required=False, default=None)
			parser.add_argument("--diskType", required=False, default=None)
			parser.add_argument("--cores", required=False, default=1)
			parser.add_argument("--mem", required=False, default=1)
			parser.add_argument("--inputs", required=False, default=None)
			parser.add_argument("--outputs", required=False, default=None)
			parser.add_argument("--env", required=False, default=None)
			parser.add_argument("--tag", required=False, default=None)
			parser.add_argument("--preemptible", action="store_true", default=False)
			parser.add_argument("--syncOutputs", required=False, default=None)

			args = parser.parse_args(args=unknown)
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, JOBS_CREATE_EXP, data=vars(args))
			print resp.get("msg")

		elif args.jobsOperation == "edit":
			parser.add_argument("--pipeline")
			parser.add_argument("--logsPath")
			parser.add_argument("--imageName")
			editGrp = parser.add_mutually_exclusive_group()
			editGrp.add_argument("--scriptUrl")
			editGrp.add_argument("--cmd")
			parser.add_argument("--cores")
			parser.add_argument("--mem")
			parser.add_argument("--diskSize")
			parser.add_argument("--diskType")
			parser.add_argument("--inputs")
			parser.add_argument("--outputs")
			parser.add_argument("--env")
			parser.add_argument("--preemptible")
			parser.add_argument("--syncOutputs")
			parser.add_argument("jobId", required=True)

			args = parser.parse_args(args=unknown)

			uri = "{route}?{query}"
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, JOB_EDIT_EXP, data=vars(args))
			print resp.get("msg")

		elif args.jobsOperation == "list":
			parser.add_argument("--pipeline", required=False, default=None)
			parser.add_argument("--tag", required=False, default=None)
			parser.add_argument("--status", choices=["running", "waiting", "succeeded", "failed", "error", "preempted"], required=False, default=None)
			parser.add_argument("--createTimeAfter", required=False, default=None)
			parser.add_argument("--limit", required=False, default=None)

			aggregation = parser.add_mutually_exclusive_group(required=True)
			aggregation.add_argument("--union", action='store_true', default=False)
			aggregation.add_argument("--intersection", action='store_true', default=True)  # will this work?
			aggregation.add_argument("--complement", action='store_true', default=False)

			args = parser.parse_args(args=unknown)

			uri = "{route}?{query}"
			query = ["select={select}".format(select=','.join(["job_id", "operation_id", "pipeline_name", "tag", "current_status", "create_time", "preemptions"])), "operation={op}".format(op=args.aggregation)]

			if args.pipeline:
				query.append("pipeline={p}".format(p=args.pipeline))

			elif args.tag:
				query.append("tag={t}".format(t=args.tag))

			elif args.status:
				query.append("status={s}".format(s=args.status))

			elif args.createTimeAfter:
				query.append("createTimeAfter={c}".format(c=args.createTimeAfter))

			elif args.limit:
				query.append("limit={l}".format(l=args.limit))

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri.format(route="/jobs", query='&'.join(query)))
			jobs = json.loads(resp.get("jobs"))


			def fieldPadding(maxLen, actualLen):
				return ''.join([' ' for x in range(maxLen - actualLen + 4)])

			header = "JOBID%sPIPELINE%sOPERATION ID%sTAG%sSTATUS%sCREATE TIME%sPREEMPTIONS\n"
			jobStatusString = "{jobId}%s{pipeline}%s{operationId}%s{tag}%s{status}%s{createTime}%s{preemptions}\n"

			if len(jobs) > 0:
				jobStrings = []

				jobIdLengths = [len(str(x.job_id)) if x.job_id is not None else len(str("None")) for x in jobs]
				jobIdLengths.append(len("JOBID"))
				maxJobIdLen = max(jobIdLengths)

				pipelineLengths = [len(x.pipeline_name) if x.pipeline_name is not None else len(str("None")) for x in
				                   jobs]
				pipelineLengths.append(len("PIPELINE"))
				maxPipelineLen = max(pipelineLengths)

				operationIdLengths = [len(x.operation_id) if x.operation_id is not None else len(str("None")) for x in
				                      jobs]
				operationIdLengths.append(len("OPERATION ID"))
				maxOperationIdLen = max(operationIdLengths)

				statusLengths = [len(x.current_status) if x.current_status is not None else len(str("None")) for x in
				                 jobs]
				statusLengths.append(len("STATUS"))
				maxStatusLen = max(statusLengths)

				tagLengths = [len(x.tag) if x.tag is not None else len(str("None")) for x in jobs]
				tagLengths.append(len("TAG"))
				maxTagLen = max(tagLengths)

				createTimeLengths = [len(x.create_time) if x.create_time is not None else len(str("None")) for x in
				                     jobs]
				createTimeLengths.append(len("CREATE TIME"))
				maxCreateTimeLen = max(createTimeLengths)

				jobStrings.append \
					(header % (fieldPadding(maxJobIdLen, len("JOBID")), fieldPadding(maxPipelineLen, len("PIPELINE")),
					           fieldPadding(maxOperationIdLen, len("OPERATION ID")),
					           fieldPadding(maxTagLen, len("TAG")),
					           fieldPadding(maxStatusLen, len("STATUS")),
					           fieldPadding(maxCreateTimeLen, len("CREATE TIME"))))

				for j in jobs:
					if j.create_time is not None:
						ct = j.create_time
					else:
						ct = "None"
					if j.operation_id is not None:
						op = j.operation_id
					else:
						op = "None"

					jobStrings.append \
						(jobStatusString.format(jobId=j.job_id, pipeline=j.pipeline_name, operationId=op, tag=j.tag,
						                        status=j.current_status, createTime=ct, preemptions=j.preemptions) % (
							 fieldPadding(maxJobIdLen, len(str(j.job_id))),
							 fieldPadding(maxPipelineLen, len(j.pipeline_name)),
							 fieldPadding(maxOperationIdLen, len(op)), fieldPadding(maxTagLen, len(j.tag)),
							 fieldPadding(maxStatusLen, len(j.current_status)),
							 fieldPadding(maxCreateTimeLen, len(ct))))

				for s in jobStrings:
					print s

		elif args.jobsOperation == "describe":
			parser.add_argument("jobId")

			args = parser.parse_args(args=unknown)
			query = "jobId={j}".format(j=args.jobId)
			uri = "{route}?{query}".format(route="/jobs", query=query)
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri)

			# TODO: pretty print response

		elif args.jobsOperation == "cancel":  # TODO: make sure that the sql expression ORs these values to get the result
			parser.add_argument("--jobId")
			parser.add_argument("--pipeline")
			parser.add_argument("--tag")

			aggregation = parser.add_mutually_exclusive_group(required=True)
			aggregation.add_argument("--union", action='store_true', default=False)
			aggregation.add_argument("--intersection", action='store_true', default=True)  # will this work?
			aggregation.add_argument("--complement", action='store_true', default=False)

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, JOB_CANCEL_EXP, data=vars(args))
			print resp.get("msg")

		elif args.jobsOperation == "restart":  # TODO: start here
			restartGrp = parser.add_mutually_exclusive_group()
			restartGrp.add_argument("--jobId")
			restartGrp.add_argument("--tag")
			restartGrp.add_argument("--preempted", action="store_true")

			args = parser.parse_args(args=unknown)

			query = "?preempted={preempted}".format(preempted=bool(args.preempted))
			uri = "{route}{query}".format(route=JOB_RESTART_EXP, query=query)

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri, data=vars(args))
			print resp.get("msg")

	elif args.subcommand == "data-disks":
		parser = argparse.ArgumentParser()

		if args.dataDisksOperation == "create":
			parser.add_argument("--inputs", required=True)
			parser.add_argument("--zone", required=False)
			parser.add_argument("diskName")

			args = parser.parse_args(args=unknown)

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, DATADISKS_CREATE_EXP, data=vars(args))
			print resp.get("msg")

		elif args.dataDisksOperation == "delete":
			parser.add_argument("--zone", required=False)
			parser.add_argument("diskName")

			args = parser.parse_args(args=unknown)

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, DATADISKS_DELETE_EXP, data=vars(args))
			print resp.get("msg")

		elif args.dataDisksOperation == "list":
			parser.add_argument("--zone", required=False)
			parser.add_argument("diskName")

			args = parser.parse_args(args=unknown)
			query = ["diskName={d}".format(d=args.diskName)]

			if args.zone:
				query.append("zone={z}".format(z=args.zone))

			uri = "{route}?{query}".format(route=DATADISKS_LIST_EXP, query='&'.join(query))
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri)

			# TODO: pretty print response

		elif args.dataDisksOperation == "describe":
			parser.add_argument("diskName")

			args = parser.parse_args(args=unknown)
			query = "diskName={d}".format(d=args.diskName)
			uri = "{route}?{query}".format(route=DATADISKS_DESCRIBE_EXP, query=query)
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri)

			# TODO: pretty print response

	elif args.subcommand == "logs":
		parser = argparse.ArgumentParser()

		if args.logsOperation == "display":
			parser.add_argument("jobId")

			args = parser.parse_args(args=unknown)
			query = "jobId={j}".format(jobId=args.jobId)

			uri = "{route}?{query}".format(route=LOG_GET_EXP, query=query)
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, uri)

			try:
				stdoutLogFile = subprocess.check_output(["gsutil", "cat", os.path.join(resp["gcs_log_path"], resp["stdout_log_path"])])
			except subprocess.CalledProcessError as e:
				print "Couldn't get the stdout log : {reason}".format(reason=e)
				exit(-1)

			print "STDOUT:\n"
			print stdoutLogFile
			print "---------\n"


			try:
				stderrLogFile = subprocess.check_output(["gsutil", "-q", "cat", os.path.join(resp["gcs_log_path"], resp["stdout_log_path"])])

			except subprocess.CalledProcessError as e:
				print "Couldn't get the stderr log : {reason}".format(reason=e)

			print "STDERR:\n"
			print stderrLogFile
			print "---------\n"

	elif args.subcommand == "scheduler":  # TODO: check to see if config file exists -- if so, check the configuration for enabled extensions; otherwise report an error if the scheduler subcommand is used
		config = PipelineConfig(CLIENT_CONFIG_PATH)
		user = os.environ["USER"]

		if args.schedulerOperation == "stop":
			PipelineScheduler.stopScheduler()
		elif args.schedulerOperation == "start":
			PipelineScheduler.startScheduler(config, user)
		else:
			print "ERROR: unrecognized option {o}".format(o=args.startOrStop)
			exit(-1)

	elif args.subcommand == "config":
		parser = argparse.ArgumentParser()

		if args.configOperation == "update":
			parser.add_argument("--projectId")
			parser.add_argument("--zones")
			parser.add_argument("--serviceAccount")
			parser.add_argument("--autorestartPreempted")
			# TODO: possibly add more args

			args = parser.parse_args(args=unknown)

			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, CONFIG_EDIT_EXP, data=vars(args))
			print resp.get("msg")

				# TODO: move code below to another location
				#config = PipelineConfig(CLIENT_CONFIG_PATH)
				#section, option = args.parameter.split('/')
				#try:
				#	config.update(section, option, value)
				#except ValueError as e:
				#	print "ERROR: couldn't update the configuration : {reason}".format(reason=e)
				#	exit(-1)

		elif args.configOperation == "view":
			resp = PipelineService.sendRequest(config.service_endpoint, config.service_port, CONFIG_VIEW_EXP)

			# TODO: pretty print response
