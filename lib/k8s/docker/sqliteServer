#!/usr/bin/env python
import os
import re
import json
import webapp2
import argparse

from StringIO import StringIO
from paste import httpserver
from pipelines.routes import *
from pipelines.config import PipelineConfig, PipelineConfigError
from pipelines.db import PipelineDatabase, PipelineDatabaseError
from pipelines.scheduler import PipelineScheduler, PipelineSchedulerError


CONFIG = PipelineConfig(path=os.environ["PIPELINES_CONFIG"])
PIPELINES_DB = PipelineDatabase(CONFIG)


class SqliteServerError(Exception):
	def __init__(self, msg):
		super(SqliteServerError, self).__init__()


class SqliteWriter(webapp2.RequestHandler):
	def post(self):
		data = json.loads(self.request.body)
		resp = None
		status = None

		if re.match(SQLITE_INSERT, self.request.path):
			# request format:
			#
			# {
			#   <key-value pairs for each column in the table>
			# }
			#
			table = os.path.basename(self.request.path)
			try:
				id = PIPELINES_DB.insert(table, **data)

			except PipelineDatabaseError as e:
				resp = {
					"msg": e
				}
				status = 400

			else:
				resp = {
					"id": id
				}

		elif re.match(SQLITE_UPDATE, self.request.path):
			table = os.path.basename(self.request.path)
			# request format:
			# {
			#   "updates": { ... < column values to update > ... },
			#   "criteria": {
			#      "operation": "AND"|"OR"|"NOT",
			#      "values": [
			#          {
			#             "operation": ...,
			#             "values": [ ... ]
			#          } | {
			#          {
			#            "key": <column-name>,
			#            "value": <column-value>
			#          }, ...
			#      ]
			#   }
			# }
			#
			try:
				PIPELINES_DB.update(table, data["updates"], data["criteria"])

			except PipelineDatabaseError as e:
				resp = {
					"msg": e
				}
				status = 400

			else:
				status = 204

		elif re.match(SQLITE_INCR_VALUE, self.request.path):
			# request format:
			#
			# {
			#   "incrementColumn": <column-name>,
			#   "incrementBy": <n>,
			#   "criteria": { ... see criteria in requests above ... }
			# }
			#
			table = os.path.basename(self.request.path)
			try:
				PIPELINES_DB.increment(table, data["incrementColumn"], data["incrementBy"], data["criteria"])

			except PipelineDatabaseError as e:
				resp = {
					"msg": e
				}
				status = 400

			else:
				status = 204

		else:
			self.response.set_status(404, "Resource {r} not found".format(r=self.request.path))

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)


class SqliteReader(webapp2.RequestHandler):
	def get(self):
		data = json.loads(self.request.body)
		resp = None
		status = None

		if re.match(SQLITE_READ, self.request.path):
			# request format:
			# {
			#   "select": [ ... column values to select ... ],
			#   "criteria": {
			#      "operation": "AND"|"OR"|"NOT",
			#      "values": [
			#          {
			#             "operation": ...,
			#             "values": [ ... ]
			#          } | {
			#          {
			#            "key": <column-name>,
			#            "value": <column-value>
			#          }, ...
			#      ]
			#   }
			# }
			#
			table = os.path.basename(self.request.path)
			try:
				resp = PIPELINES_DB.select(table, data["select"], data["criteria"])

			except PipelineDatabaseError as e:
				resp = {
					"msg": e
				}
				status = 400

			else:
				status = 200

		else:
			self.response.set_status(404, "Resource {r} not found".format(r=self.request.path))

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)


app = webapp2.WSGIApplication([
	(SQLITE_READ, SqliteReader),
	(SQLITE_INSERT, SqliteWriter),
	(SQLITE_UPDATE, SqliteWriter),
	(SQLITE_INCR_VALUE, SqliteWriter),
], debug=True)


def main(host, port):
	jobs = {
		"job_id": "INTEGER PRIMARY KEY AUTOINCREMENT",
		"operation_id": "VARCHAR(128)",
		"instance_name": "VARCHAR(128)",
		"pipeline_name": "VARCHAR(128)",
		"tag": "VARCHAR(128)",
		"current_status": "VARCHAR(128)",
		"preemptions": "INTEGER",
		"gcs_log_path": "VARCHAR(128)",
		"stdout_log": "VARCHAR(128)",
		"stderr_log": "VARCHAR(128)",
		"create_time": "VARCHAR(128)",
		"end_time": "VARCHAR(128)",
		"processing_time": "FLOAT",
		"request": "TEXT"
	}

	jobDeps = {
		"row_id": "INTEGER PRIMARY KEY AUTOINCREMENT",
		"parent_id": "INTEGER",
		"child_id": "INTEGER"
	}

	jobArchive = {
		"row_id": "INTEGER PRIMARY KEY AUTOINCREMENT",
		"job_id": "INTEGER",
		"operation_id": "VARCHAR(128)",
		"instance_name": "VARCHAR(128)",
		"pipeline_name": "VARCHAR(128)",
		"tag": "VARCHAR(128)",
		"current_status": "VARCHAR(128)",
		"preemptions": "INTEGER",
		"gcs_log_path": "VARCHAR(128)",
		"stdout_log": "VARCHAR(128)",
		"stderr_log": "VARCHAR(128)",
		"create_time": "VARCHAR(128)",
		"end_time": "VARCHAR(128)",
		"processing_time": "FLOAT",
		"request": "TEXT"
	}

	dataDisks = {
		"row_id": "INTEGER PRIMARY KEY AUTOINCREMENT",
		"job_id": "INTEGER",
		"disk_name": "VARCHAR(128)",
		"disk_zone": "VARCHAR(128)"
	}

	try:
		PIPELINES_DB.create("jobs", "table", jobs)
		PIPELINES_DB.create("job_dependencies", "table", jobDeps)
		PIPELINES_DB.create("job_archive", "table", jobArchive)
		PIPELINES_DB.create("data_disks", "table", dataDisks)

	except PipelineDatabaseError as e:
		raise SqliteServerError("Couldn't bootstrap server: {reason}".format(reason=e))

	httpserver.serve(app, host=host, port=port)


if __name__ == "__main__":
	parser = argparse.ArgumentParser()
	parser.add_argument("--host", required=False, default="0.0.0.0")
	parser.add_argument("--port", required=True)
	args = parser.parse_args()
	main(args.host, args.port)
