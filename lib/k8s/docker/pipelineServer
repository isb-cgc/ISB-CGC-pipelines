#!/usr/bin/env python
import os
import re
import json
import webapp2
import argparse

from ConfigParser import SafeConfigParser
from StringIO import StringIO
from paste import httpserver
from pipelines.routes import *
from pipelines.queue import PipelineQueue, PipelineQueueError
from pipelines.schema import PipelineSchema, PipelineSchemaValidationError, PipelineSubmitError
from pipelines.builder import PipelineBuilder
from pipelines.config import PipelineConfig
from pipelines.service import PipelineService, PipelineServiceError
import pipelines.service.DataDisk
import pipelines.service.DataDiskError


CONFIG = PipelineConfig(path=os.environ["PIPELINES_CONFIG"])

SQLITE_READER_SERVICE_HOST = os.environ["SQLITE_READER_SERVICE_HOST"]
SQLITE_READER_SERVICE_PORT = os.environ["SQLITE_READER_SERVICE_PORT"]

SQLITE_WRITER_SERVICE_HOST = os.environ["SQLITE_WRITER_SERVICE_HOST"]
SQLITE_WRITER_SERVICE_PORT = os.environ["SQLITE_WRITER_SERVICE_PORT"]

CONFIG_WRITER_SERVICE_HOST = os.environ["CONFIG_WRITER_SERVICE_HOST"]
CONFIG_WRITER_SERVICE_PORT = os.environ["CONFIG_WRITER_SERVICE_PORT"]


class Jobs(webapp2.RequestHandler):
	def get(self):
		if re.match(JOBS_GET_EXP, self.request.path):
			queryParams = {x.split('=')[0]: x.split('=')[1] for x in self.request.query_string.split('&')}

			req = {
				"select": [],
				"criteria": {
					"operation": "AND",
					"values": [{"key": k, "value": v} for k, v in queryParams.iteritems()]
				}
			}

			try:
				jobsList = PipelineService.sendRequest(SQLITE_READER_SERVICE_HOST, SQLITE_READER_SERVICE_PORT, "/read/jobs", data=req, protocol="tcp")

			except PipelineServiceError as e:
				self.response.set_status(400, e)

			else:
				resp = {
					"jobs": jobsList.json()["data"]
				}

				status = 200

		else:
			status = 404
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}

		self.response.out = StringIO(json.dumps(resp))
		self.response.set_status(status)

	def post(self):
		kwargs = json.loads(self.request.body)
		resp = None
		status = None

		if re.match(JOBS_CREATE_EXP, self.request.path):
			pipelineSpec = PipelineSchema(CONFIG, **kwargs)
			pipelineBuilder = PipelineBuilder(CONFIG)
			pipelineBuilder.addStep(pipelineSpec)

			try:
				jobId = pipelineBuilder.run()

			except PipelineSchemaValidationError as e:
				resp = {
					"msg": "Couldn't submit job: {reason}".format(reason=e)
				}
				status = 400

			except PipelineSubmitError as e:
				resp = {
					"msg": "Couldn't submit job: {reason}".format(reason=e)
				}
				status = 400

			else:
				resp = {
					"job_id": jobId
				}
				status = 201

		elif re.match(JOBS_EDIT_EXP, self.request.path):
			queryParams = {x.split('=')[0]: x.split('=')[1] for x in self.request.query_string.split('&')}
			req = {
				"updates": kwargs,
				"criteria": {
					"operation": "AND",
					"values": [
						{
							"key": "job_id",
							"value": queryParams["job_id"]
						}
					]
				}
			}

			try:
				PipelineService.sendRequest(SQLITE_WRITER_SERVICE_HOST, SQLITE_WRITER_SERVICE_PORT, "/update/jobs", data=req, protocol="tcp")

			except PipelineServiceError as e:
				status = 400
				resp = {
					"msg": "Couldn't edit job: {reason}".format(reason=e)
				}

			else:
				status = 204

		elif re.match(JOBS_RESTART_EXP, self.request.path):
			pipelineQueue = PipelineQueue('WAIT_Q', host=os.environ["RABBITMQ_SERVICE_HOST"], port=os.environ["RABBITMQ_SERVICE_PORT"])

			req = {
				"select": ["job_id", "request"],
				"criteria": {
					"operation": "OR",
					"values": [{"key": k, "value": v} for k, v in kwargs.iteritems()]
				}
			}

			try:
				jobInfo = PipelineService.sendRequest(SQLITE_READER_SERVICE_HOST, SQLITE_READER_SERVICE_PORT, "/jobs", data=req, protocol="tcp")

			except PipelineServiceError as e:
				status = 400
				resp = {
					"msg": "Couldn't restart job: {reason}".format(reason=e)
				}

			else:
				errors = []
				for j in jobInfo:
					msg = {
						"job_id": j["job_id"],
						"request": json.loads(j["request"])
					}

					try:
						pipelineQueue.publish(json.dumps(msg))

					except PipelineQueueError as e:
						status = 400
						errors.append("Couldn't restart pipeline: {reason}".format(reason=e))
					else:
						continue

				if len(errors) > 0:
					resp = {
						"errors": errors
					}
					status = 202
				else:
					status = 204

		elif re.match(JOBS_CANCEL_EXP, self.request.path):
			pipelineQueue = PipelineQueue('CANCEL_Q', host=os.environ["RABBITMQ_SERVICE_HOST"], port=os.environ["RABBITMQ_SERVICE_PORT"])

			req = {
				"select": ["current_status", "operation_id", "job_id"],
				"criteria": {
					"operation": "OR",
					"values": [{"key": k, "value": v} for k, v in kwargs.iteritems()]
				}
			}

			try:
				jobInfo = PipelineService.sendRequest(os.environ["SQLITE_READER_SERVICE_HOST"], os.environ["SQLITE_READER_SERVICE_PORT"], "/jobs", data=req, protocol="tcp")

			except PipelineServiceError as e:
				resp = {
					"msg": "Couldn't stop pipeline: {reason}".format(reason=e)
				}
				status = 400
			else:
				errors = []
				for j in jobInfo:
					if j["current_status"] == "RUNNING":
						msg = {
							"job_id": j["job_id"],
							"operation_id": j["operation_id"]
						}
						try:
							pipelineQueue.publish(json.dumps(msg))
						except PipelineQueueError as e:
							status = 400
							errors.append("Couldn't cancel pipeline: {reason}".format(reason=e))
						else:
							continue

					if len(errors) > 0:
						resp = {
							"errors": errors
						}
						status = 202
					else:
						status = 204

		else:
			status = 404
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)

class Config(webapp2.RequestHandler):
	def post(self):
		data = json.load(self.request.body)
		resp = None
		status = None

		if re.match(CONFIG_EDIT_EXP, self.request.path):
			req = json.loads(self.request.body)

			try:
				PipelineService.sendRequest(CONFIG_WRITER_SERVICE_HOST, CONFIG_WRITER_SERVICE_PORT, data=req, protocol="tcp")

			except PipelineServiceError as e:
				resp = {
					"msg": "Couldn't edit the configuration: {reason}".format(reason=e)
				}
				status = 400
			else:
				status = 204

		else:
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}
			status = 404

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)

	def get(self):
		resp = {}
		status = None

		if re.match(CONFIG_VIEW_EXP, self.request.path):
			c = SafeConfigParser()

			with open(CONFIG.path) as f:
				c.read(f)

			sections = c.sections()

			for s in sections:
				resp[s] = dict(s.items())

		else:
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}
			status = 404

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)


class DataDisk(webapp2.RequestHandler):
	def post(self):
		data = json.loads(self.request.body)
		resp = None
		status = None

		if re.match(DATADISKS_CREATE_EXP, self.request.path):
			# request format:
			# {
			#   "diskName": <disk-name>,
			#   "diskType": <disk-type>|None,
			#   "diskSize": <disk-size>,
			#   "zone": <zone>|None
			# }
			#

			try:
				pipelines.service.disks.DataDisk.create(CONFIG, **data)

			except pipelines.service.disks.DataDiskError as e:
				resp = {
					"msg": e
				}
				status = 400
			else:
				try:
					PipelineService.sendRequest(SQLITE_WRITER_SERVICE_HOST, SQLITE_WRITER_SERVICE_PORT, "/write/datadisks", data=data, protocol="tcp")
				except PipelineServiceError as e:
					resp = {
						"msg": "Disk created successfully, but not recorded: {reason}".format(reason=e)
					}
					status = 202

				else:
					status = 204

		elif re.match(DATADISKS_DELETE_EXP, self.request.path):
			# request format:
			# {
			#   "disk_name": <disk-name>,
			#   "disk_zone": <zone>|None
			# }
			#
			pipelines.service.DataDisk.delete(CONFIG, **data)  # TODO: args

		else:
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}
			status = 404

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)

	def get(self):
		resp = None
		status = None

		if re.match(DATADISKS_GET_EXP, self.request.path):
			queryParams = {x.split('=')[0]: x.split('=')[1] for x in self.request.query_string.split('&')}

			try:
				disks = PipelineService.sendRequest(SQLITE_READER_SERVICE_HOST, SQLITE_READER_SERVICE_PORT, "/read/datadisks", data=queryParams, protocol="tcp")

			except PipelineServiceError as e:
				resp = {
					"msg": "Couldn't get disk information: {reason}".format(reason=e)
				}
				status = 400

			else:
				resp = {
					"disks": disks
				}
				status = 200

		else:
			resp = {
				"msg": "Resource {r} not found".format(r=self.request.path)
			}
			status = 404

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)


class Log(webapp2.RequestHandler):
	def get(self):
		resp = None
		status = None

		if re.match(LOGS_GET_EXP, self.request.path):
			jobId = os.path.basename(self.request.path)

			req = {
				"select": ["stdout_log", "stderr_log", "gcs_log_path"],
				"criteria": {
					"operation": "AND",
					"values": [
						{
							"key": "job_id",
							"value": jobId
						}
					]
				}
			}

			try:
				jobLogs = PipelineService.sendRequest(os.environ["SQLITE_READER_SERVICE_HOST"], os.environ["SQLITE_READER_SERVICE_PORT"], "/read/jobs", data=req, protocol="tcp")

			except PipelineServiceError as e:
				resp = {
					"msg": "Couldn't get job logs: {reason}".format(reason=e)
				}
				status = 400

			else:
				resp = {
					"logs": jobLogs
				}
				status = 200

		else:
			self.response.set_status(404, "Resource {r} not found".format(r=self.request.path))

		if resp is not None:
			self.response.out = StringIO(json.dumps(resp))

		self.response.set_status(status)


app = webapp2.WSGIApplication([
	(JOBS_CREATE_EXP, Jobs),
	(JOBS_GET_EXP, Jobs),
	(JOBS_EDIT_EXP, Jobs),
	(JOBS_CANCEL_EXP, Jobs),
	(JOBS_RESTART_EXP, Jobs),
	(CONFIG_VIEW_EXP, Config),
	(CONFIG_EDIT_EXP, Config),
	(DATADISKS_GET_EXP, DataDisk),
	(DATADISKS_CREATE_EXP, DataDisk),
	(DATADISKS_DELETE_EXP, DataDisk),
	(LOGS_GET_EXP, Log),
], debug=True)


def main(host, port):
	httpserver.serve(app, host=host, port=port)


if __name__ == "__main__":
	parser = argparse.ArgumentParser()
	parser.add_argument("--host", required=False, default="0.0.0.0")
	parser.add_argument("--port", required=False, default=80)
	args = parser.parse_args()
	main(args.host, args.port)
